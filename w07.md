---
permalink: /W07/
---

#### [cd ../](../)

# Top 10 List of Week 07

1. ***[Process Synchronization](https://www.studytonight.com/operating-system/process-synchronization)***

   Process Synchronization means sharing system resources by processes in a such a way that, Concurrent access to shared data is handled thereby minimizing the chance of inconsistent data. Maintaining data consistency demands mechanisms to ensure synchronized execution of cooperating processes. Process Synchronization was introduced to handle problems that arose while multiple process are executed.

2. ***[Critical Section Problem](https://www.studytonight.com/operating-system/process-synchronization)***

   A Critical Section is a code segment that accesses shared variables and has to be executed as an atomic action. It means that in a group of cooperating processes, at a given point of time, only one process must be executing its critical section. If any other process also wants to execute its critical section, it must wait until the first one finishes.

3. ***[Mutex Locks](https://www.studytonight.com/operating-system/process-synchronization)***

   As the synchronization hardware solution is not easy to implement for everyone, a strict software approach called Mutex Locks was introduced. In this approach, in the entry section of code, a LOCK is acquired over the critical resources modified and used inside critical section, and in the exit section that LOCK is released. As the resource is locked while a process executes its critical section hence no other process can access it.

4. ***[Peterson's Solution](https://www.geeksforgeeks.org/petersons-algorithm-in-process-synchronization/)***

   Peterson’s Algorithm is used to synchronize two processes. It uses two variables, a bool array flag of size 2 and an int variable turn to accomplish it. In the solution i represents the Consumer and j represents the Producer. Initially the flags are false. When a process wants to execute it’s critical section, it sets it’s flag to true and turn as the index of the other process. This means that the process wants to execute but it will allow the other process to run first. The process performs busy waiting until the other process has finished it’s own critical section. After this the current process enters it’s critical section and adds or removes a random number from the shared buffer. After completing the critical section, it sets it’s own flag to false, indication it does not wish to execute anymore.

5. ***[Semaphores](https://www.geeksforgeeks.org/semaphores-in-process-synchronization/)***

   Semaphore is simply a variable which is non-negative and shared between threads. This variable is used to solve the critical section problem and to achieve process synchronization in the multiprocessing environment. 

   Semaphores are of two types:

   1. **Binary Semaphore:** This is also known as mutex lock. It can have only two values – 0 and 1. Its value is initialized to 1. It is used to implement the solution of critical section problem with multiple processes.
   2. **Counting Semaphore:** Its value can range over an unrestricted domain. It is used to control access to a resource that has multiple instances

6. ***[Semaphores in C](https://www.geeksforgeeks.org/use-posix-semaphores-c/)***

   Semaphores are very useful in process synchronization and multithreading. But how to use one in real life, for example say in C Language? The POSIX system in Linux presents its own built-in semaphore library. To use it, we have to :

   1. Include semaphore.h
   2. Compile the code by linking with -lpthread -lrt

   To lock a semaphore we can use the `sem_wait` function, to release or signal one we use the `sem_post`, and to intialize one we use `sem_init`.

7. ***[Deadlock Characterization](https://www.tutorialspoint.com/deadlock-characterization)***

   A deadlock happens in operating system when two or more processes need some resource to complete their execution that is held by the other process. There are 4 types of deadlocks: 

   - **Mutual Exclusion:** There should be a resource that can only be held by one process at a time. In the diagram below, there is a single instance of Resource 1 and it is held by Process 1 only.
   - **Hold and Wait:** A process can hold multiple resources and still request more resources from other processes which are holding them. In the diagram given below, Process 2 holds Resource 2 and Resource 3 and is requesting the Resource 1 which is held by Process 1.
   - **No Preemption:** A resource cannot be preempted from a process by force. A process can only release a resource voluntarily. In the diagram below, Process 2 cannot preempt Resource 1 from Process 1. It will only be released when Process 1 relinquishes it voluntarily after its execution is complete.
   - **Circular Wait:** A process is waiting for the resource held by the second process, which is waiting for the resource held by the third process and so on, till the last process is waiting for a resource held by the first process. This forms a circular chain. For example: Process 1 is allocated Resource2 and it is requesting Resource 1. Similarly, Process 2 is allocated Resource 1 and it is requesting Resource 2. This forms a circular wait loop.

8. ***[Bankers Algorithm](https://www.geeksforgeeks.org/deadlock-prevention/)***

   Bankers’s Algorithm is resource allocation and deadlock avoidance algorithm which test all the request made by processes for resources, it checks for the safe state, if after granting request system remains in the safe state it allows the request and if there is no safe state it doesn’t allow the request made by the process.

9. ***[Deadlock Handling Strategies](https://www.javatpoint.com/os-strategies-for-handling-deadlock)***

   1. **Deadlock Ignorance:** This is being used by many operating systems mainly for end user uses. In this approach, the Operating system assumes that deadlock never occurs. It simply ignores deadlock. This approach is best suitable for a single end user system where User uses the system only for browsing and all other normal stuff.
   2. **Deadlock Prevention:** Deadlock happens only when Mutual Exclusion, hold and wait, No preemption and circular wait holds simultaneously. If it is possible to violate one of the four conditions at any time then the deadlock can never occur in the system. The idea behind the approach is very simple that we have to fail one of the four conditions but there can be a big argument on its physical implementation in the system.
   3. **Deadlock Avoidance:** In deadlock avoidance, the operating system checks whether the system is in safe state or in unsafe state at every step which the operating system performs. The process continues until the system is in safe state. Once the system moves to unsafe state, the OS has to backtrack one step. In simple words, The OS reviews each allocation so that the allocation doesn't cause the deadlock in the system.
   4. **Deadlock Detection and Discovery**: This approach let the processes fall in deadlock and then periodically check whether deadlock occur in the system or not. If it occurs then it applies some of the recovery methods to the system to get rid of deadlock.

10. ***[Recovering From a Deadlock](https://www.os-book.com/OS9/slide-dir/index.html)***

    When a detection algorithm determines that a deadlock exists, several alter- natives are available. One possibility is to inform the operator that a deadlock has occurred and to let the operator deal with the deadlock manually. Another possibility is to let the system recover from the deadlock automatically. There are two options for breaking a deadlock. One is simply to abort one or more threads to break the circular wait. The other is to preempt some resources from one or more of the deadlocked threads.


#### [cd ../](../)