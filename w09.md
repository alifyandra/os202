---
permalink: /W09/
---

#### [cd ../](../)

# Top 10 List of Week 09

1. ***[CPU Scheduling](https://www.studytonight.com/operating-system/cpu-scheduling#)***

   CPU scheduling is a process which allows one process to use the CPU while the execution of another process is on hold(in waiting state) due to unavailability of any resource like I/O etc, thereby making full use of CPU. The aim of CPU scheduling is to make the system efficient, fast and fair.
   
   Whenever the CPU becomes idle, the operating system must select one of the processes in the ready queue to be executed. The selection process is carried out by the short-term scheduler (or CPU scheduler). The scheduler selects from among the processes in memory that are ready to execute, and allocates the CPU to one of them.
   
2. ***[CPU-I/O Burst Cycle](https://www.os-book.com/OS9/slide-dir/index.html)***

   The success of CPU scheduling depends on an observed property of processes: process execution consists of a cycle of CPU execution and I/O wait. Processes alternate between these two states. Process execution begins with a CPU burst. That is followed by an I/O burst, which is followed by another CPU burst, then another I/O burst, and so on. Eventually, the final CPU burst ends with a system request to terminate execution.

3. ***[Dispatcher](https://www.os-book.com/OS9/slide-dir/index.html)***

   A component involved in the CPU-scheduling function is the dispatcher. The dispatcher is the module that gives control of the CPU’s core to the process selected by the CPU scheduler. This function involves the following:

   - Switching context from one process to another
   - Switching to user mode.
   - Jumping to the proper location in the user program to resume the program.

4. ***[Scheduling Criteria](https://www.os-book.com/OS9/slide-dir/index.html)***

   Many criteria have been suggested for comparing CPU-scheduling algo- rithms. Which characteristics are used for comparison can make a substantial difference in which algorithm is judged to be best. The criteria include the following:

   - CPU Utilization: We want to keep the CPU as busy as possible.
   - Throughput: If the CPU is busy executing processes, then work is being done.
   - Turnaround Time: The interval from the time of submission of a process to the time of completion is the turnaround time.
   - Waiting Time: Waiting time is the sum of the periods spent waiting in the ready queue.
   - Response Time: Response time is the time it takes to start responding, not the time it takes to output the response.

5. ***[(Burst) Algorithms](https://www.os-book.com/OS9/slide-dir/index.html)***

   - FCFS: One of the simplest algorithms is first come first served algorithm.
   - SJF: This algorithm associates with each process the length of the process’s next CPU burst. When the CPU is available, it is assigned to the process that has the smallest next CPU burst. If the next CPU bursts of two processes are the same, FCFS scheduling is used to break the tie.
   - RR: The round-robin (RR) scheduling algorithm is similar to FCFS scheduling, but preemption is added to enable the system to switch between processes. A small unit of time, called a time quantum or time slice, is defined. 
   - Priority Scheduling: A priority is associated with each process, and the CPU is allocated to the process with the highest priority. Equal-priority processes are scheduled in FCFS order. An SJF algorithm is simply a priority algorithm where the priority (*p*) is the inverse of the (predicted) next CPU burst. The larger the CPU burst, the lower the priority, and vice versa.
   - Multilevel Queue Scheduling: If there are multiple processes in the highest-priority queue, they are executed in round-robin order. In the most generalized form of this approach, a priority is assigned statically to each process, and a process remains in the same queue for the duration of its runtime.

6. ***[Thread Scheduling](https://www.os-book.com/OS9/slide-dir/index.html)***

   On most modern operating systems it is kernel-level threads—not processes—that are being scheduled by the operating system. User-level threads are managed by a thread library, and the kernel is unaware of them. To run on a CPU, user-level threads must ultimately be mapped to an associated kernel-level thread, although this mapping may be indirect and may use a lightweight process (LWP).

7. ***[Multi-processor Scheduling](https://www.os-book.com/OS9/slide-dir/index.html)***

   If multiple CPUs are available, load sharing, where multiple threads may run in parallel, becomes possible, however scheduling issues become correspondingly more complex. 

8. ***[Load Balancing](https://www.os-book.com/OS9/slide-dir/index.html)***

   On SMP systems, it is important to keep the workload balanced among all processors to fully utilize the benefits of having more than one processor. Oth- erwise, one or more processors may sit idle while other processors have high workloads, along with ready queues of threads awaiting the CPU. Load balanc- ing attempts to keep the workload evenly distributed across all processors in an SMP system. It is important to note that load balancing is typically necessary only on systems where each processor has its own private ready queue of eligi- ble threads to execute

9. ***[Processor Affinity](https://www.os-book.com/OS9/slide-dir/index.html)***

   Due to load balancing. The contents of cache memory must be invalidated for the first pro- cessor, and the cache for the second processor must be repopulated. Because of the high cost of invalidating and repopulating caches, most operating systems with SMP support try to avoid migrating a thread from one processor to another and instead attempt to keep a thread running on the same processor and take advantage of a warm cache. This is known as processor affinit —that is, a process has an affinity for the processor on which it is currently running.

10. ***[Linux Scheduling](https://www.os-book.com/OS9/slide-dir/index.html)***

    Scheduling in the Linux system is based on scheduling classes. Each class is assigned a specific priority. By using different scheduling classes, the kernel can accommodate different scheduling algorithms based on the needs of the system and its processes. The scheduling criteria for a Linux server, for exam- ple, may be different from those for a mobile device running Linux. To decide which task to run next, the scheduler selects the highest-priority task belong- ing to the highest-priority scheduling class. 


#### [cd ../](../)
